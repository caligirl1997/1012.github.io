<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN">
<html>
<head>
  <title>Ethical Reflections Team3</title>
   	<link rel="stylesheet" href="../styles/minimal-table.css" type="text/css">
</head>

<body>
<!-- Site navigation menu -->
<ul class="navbar">
  <li><a href="../index.html">Home</a>
  <li><a href="ethics.html">Ethical Reflections</a> 
  <li><a href="process.html">Process Support</a>
</ul>

<h1>Ethical Reflections Team Member 3</h1><br>
<p>Team name 1012</p>

<p><h4>Student name: Yena CHANG, id:20128933, </p></h4>


<h1>Ethical issues relating to AI, my personal reflections and recommendations </h1>

</ul><h2><p>INTRODUCTION<p></h2>
</ul><h4><p>Whether we like it or not, Artificial Intelligence (AI) has been deeply integrated into every facet of our lives. AI has had an impact on our interactions, our environments and have reshaped our lives.<p></h4>
</ul><h4><p>AI has enabled our society to grow and develop exponentially. In the pursuit for greatness, the question on how ethical the use of AI has been raised by many. Who is responsible if AI performs unethical acts on humans?<p></h4>
</ul><h4><p>The overriding principle when designing and developing AI systems should be to ensure that its purpose is to be beneficent and non-maleficent. That is, to do good and to do no harm. We should be able to trust that these AI systems have this principle in place to ensure that we are benefiting from a system that is fair, inclusive transparent, lawful, and equally distributes economic, social and political opportunity. There should be no persons undermined or harmed through the use of AI systems.<p></h4>
</ul><h4><p>People have a right to their privacy. Data-protection principles need to be implemented where there are necessary safeguards which meet the requirements of the General Data Protection Regulation (GDPR) in order to protect the rights of the users.<p></h4>


</ul><h2><p>MISUSE OF AI<p></h2>
</ul><h4><p>We should consider the potential downfalls through the misuse of AI systems, and who is ultimately responsible for when things go wrong.<p></h4>
</ul><h4><p>For example, in the healthcare industry, a misuse of AI systems can lead to a human fatality. The AI system may have made a mistake, but who is responsible for this mistake that has cost a human life? A possible systemic flaw that may occur may be the unfair triage in treatment decisions. AI systems may make a decision depending on a patient’s insurance status or ability to pay for their treatment. There needs to be a safeguard implemented to preserve patients’ data confidentiality.<p></h4>
</ul><h4><p>Another example can be the potential misuse of AI systems in the workplace. A possible systemic flaw may be seen in the recruitment and promotion process. AI systems may develop a bias against selecting certain genders, race, age, qualifications, appearance, etc. This has already occurred with Amazon’s recruitment system which favoured male applicants over women applicants. AI systems interpret data which has already been collated and make decisions depending on the pre-defined parameters, in order to achieve the goal which has been set. The Amazon recruitment system had based its decision making on analysing patterns in resumes which had been submitted to the company in the last ten years. Who is responsible for monitoring the candidate pool produced by AI systems, and how do we ensure that same across the board? This example highlights the vulnerability in AI systems. We need to ensure that worker’s interests and rights to privacy are protected in order to prevent the unfair displacement of workers.<p></h4>
	


</ul><h2><p>OUR RIGHTS<p></h2>
</ul><h4><p>Considering the negative impacts that AI systems may have on society, we have a right to be informed on how and when our personal information is being used. The GDPR is there to protect our data from being processed illegally, which can affect AI systems. The GDPR Article requires that personal data should be processed ‘lawfully, fairly and in a transparent manner’ in relation to the data subject. We have a right to not be given misleading information on how our personal data is being utilised, and to be informed clearly when asked to provide consent for third parties to utilise our information and who has access to this information.<p></h4>


</ul><h2><p>WHO IS RESPONSIBLE?<p></h2>
</ul><h4><p>So who should be held accountable when AI systems experience a fatal mistake? Should it be the developer, the supplier of the sample data, or the operator?<p></h4>
</ul><h4><p>The developer of the AI system may have made an error in the system’s algorithm. These errors may arise from lack of knowledge and understanding of the business model, an accidental virus, etc. In this instance, the developer of the algorithm is liable for any damages.<p></h4>
</ul><h4><p>The supplier of the sample data ‘trains’ the AI system. They supply the system with sample cases and expected outcomes. The AI system analyses the sample data results and uses the programmed algorithms to form predictions. It is important that the supplier provides the AI system with a large, diverse data sets in order to ensure the system does not become biased. Any errors that arise on the suppliers watch, they are liable.<p></h4>
</ul><h4><p>The person operating the AI system can misinterpret the conclusion reached. They can choose whether to utilise the suggestions produced by the AI machine or formulate their own decisions. Any errors made by the operator will result in them being held liable.<p></h4>



</ul><h2><p>CONCLUSION<p></h2>
</ul><h4><p>In conclusion, I do not believe that there is a single encompassing safeguard method which will protect us from the repercussions in the instance AI goes wrong. There needs to be a holistic approach to ensure that AI systems are used ethically. We have a duty to know how our information is being utilised and whether the information is being used lawfully, fairly and in a transparent manner. We can’t be turning a blind eye and trust that corporations are using our data for good. We need to be having public discussions on the real repercussions and case examples of AI going bad. If not for us, but for the sake of the future generations to come.<p></h4>



</html>
